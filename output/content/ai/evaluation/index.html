<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"/><meta content="width=device-width, initial-scale=1.0" name="viewport"/><title>Exploring AI Evaluation Platforms</title><script src="https://cdn.tailwindcss.com"></script><script src="https://cdn.jsdelivr.net/npm/chart.js"></script><link href="https://fonts.googleapis.com" rel="preconnect"/><link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap" rel="stylesheet"/><style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #FDFBF8; /* Warm Neutral */
            color: #334155;
        }
        .nav-btn {
            transition: all 0.3s ease;
            position: relative;
            padding-bottom: 8px;
        }
        .nav-btn.active::after, .nav-btn:hover::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 50%;
            transform: translateX(-50%);
            width: 60%;
            height: 2px;
            background-color: #CC5500; /* Subtle Accent */
        }
        .nav-btn.active {
            color: #1e293b;
            font-weight: 600;
        }
        .card {
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }
        .card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 15px -3px rgb(0 0 0 / 0.1), 0 4px 6px -4px rgb(0 0 0 / 0.1);
        }
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 800px;
            margin-left: auto;
            margin-right: auto;
            height: 400px;
            max-height: 50vh;
        }
        @media (max-width: 768px) {
            .chart-container {
                height: 350px;
            }
        }
        .modal-backdrop {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0,0,0,0.5);
            z-index: 40;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        .modal-content {
            background-color: #FFFFFF;
            padding: 2rem;
            border-radius: 0.5rem;
            width: 90%;
            max-width: 600px;
            max-height: 80vh;
            overflow-y: auto;
            z-index: 50;
        }
        .hidden {
            display: none;
        }
        .tag {
            display: inline-block;
            padding: 0.25rem 0.75rem;
            border-radius: 9999px;
            font-size: 0.75rem;
            font-weight: 500;
            margin-right: 0.5rem;
            margin-bottom: 0.5rem;
        }
    </style></head><body class="antialiased"><header class="bg-white/80 backdrop-blur-lg shadow-sm sticky top-0 z-30"><nav class="container mx-auto px-4 py-3 flex justify-between items-center"><h1 class="text-xl md:text-2xl font-bold text-slate-800">AI Evaluation Explorer</h1><div class="hidden md:flex items-center space-x-6 text-slate-600 font-medium" id="nav-buttons"><button class="nav-btn active" data-target="overview">Overview</button><button class="nav-btn" data-target="benchmarking">Benchmarking</button><button class="nav-btn" data-target="visualization">Visualization</button><button class="nav-btn" data-target="frameworks">Frameworks</button></div><div class="md:hidden"><select class="block w-full rounded-md border-gray-300 shadow-sm focus:border-amber-500 focus:ring-amber-500 sm:text-sm p-2 bg-white" id="mobile-nav"><option value="overview">Overview</option><option value="benchmarking">Benchmarking</option><option value="visualization">Visualization</option><option value="frameworks">Frameworks</option></select></div></nav></header><main class="container mx-auto p-4 md:p-8"><section class="space-y-8" id="overview"><div class="text-center p-8 bg-white rounded-lg shadow-md border border-slate-200"><h2 class="text-3xl md:text-4xl font-bold text-slate-800 mb-4">Navigating the AI Evaluation Landscape</h2><p class="max-w-3xl mx-auto text-slate-600 text-lg">
                    As Large Language Models (LLMs), Generative AI, and Agentic systems become more powerful, rigorously evaluating their performance, safety, and reliability is more critical than ever. This interactive guide explores the three core pillars of AI evaluation: standardized <span class="font-semibold text-teal-700">Benchmarking</span>, insightful <span class="font-semibold text-amber-700">Visualization</span>, and holistic <span class="font-semibold text-indigo-700">Evaluation Frameworks</span>. Use the navigation to explore each area and understand the tools shaping responsible AI development.
                </p></div><div class="grid md:grid-cols-3 gap-6"><div class="bg-white p-6 rounded-lg shadow-sm border border-slate-200 text-center cursor-pointer card" onclick="document.querySelector('[data-target=benchmarking]').click()"><div class="text-4xl mb-3">üìè</div><h3 class="text-xl font-bold text-teal-700 mb-2">Benchmarking</h3><p class="text-slate-600">Measuring model performance against standardized tasks and leaderboards to quantify capabilities like reasoning, coding, and knowledge.</p></div><div class="bg-white p-6 rounded-lg shadow-sm border border-slate-200 text-center cursor-pointer card" onclick="document.querySelector('[data-target=visualization]').click()"><div class="text-4xl mb-3">üëÅÔ∏è</div><h3 class="text-xl font-bold text-amber-700 mb-2">Visualization</h3><p class="text-slate-600">Using observability and explainability tools to understand model behavior, debug issues, and trace the lifecycle of AI-powered applications.</p></div><div class="bg-white p-6 rounded-lg shadow-sm border border-slate-200 text-center cursor-pointer card" onclick="document.querySelector('[data-target=frameworks]').click()"><div class="text-4xl mb-3">üõ°Ô∏è</div><h3 class="text-xl font-bold text-indigo-700 mb-2">Frameworks</h3><p class="text-slate-600">Applying structured approaches to assess broader qualities like fairness, robustness, and safety that go beyond simple accuracy metrics.</p></div></div></section><section class="hidden space-y-8" id="benchmarking"><div class="bg-white p-6 rounded-lg shadow-md border border-slate-200"><h2 class="text-3xl font-bold text-teal-700 mb-2">Benchmarking: Quantifying AI Capabilities</h2><p class="text-slate-600 max-w-4xl">
                    Benchmarking is the process of evaluating LLMs on a standardized set of tasks to produce comparable, quantitative scores. These platforms often aggregate results into public leaderboards, driving competition and tracking progress in the field. Below, you can see a comparison of what different popular benchmarks focus on and explore details for each platform.
                </p></div><div class="bg-white p-6 rounded-lg shadow-md border border-slate-200"><h3 class="text-xl font-semibold text-center text-slate-800 mb-4">Benchmark Focus Areas Comparison</h3><div class="chart-container"><canvas id="benchmarkChart"></canvas></div></div><div class="bg-white p-6 rounded-lg shadow-md border border-slate-200"><h3 class="text-xl font-semibold text-slate-800 mb-4">Explore Benchmark Platforms</h3><div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6" id="benchmark-cards"></div></div></section><section class="hidden space-y-8" id="visualization"><div class="bg-white p-6 rounded-lg shadow-md border border-slate-200"><h2 class="text-3xl font-bold text-amber-700 mb-2">Visualization &amp; Explainability</h2><p class="text-slate-600 max-w-4xl">
                    While benchmarks tell us *what* a model can do, visualization and observability tools help us understand *how* and *why*. These platforms are crucial for debugging complex AI systems, monitoring their behavior in production, and gaining insights into the full lifecycle of an LLM-powered application.
                </p></div><div class="bg-white p-6 rounded-lg shadow-md border border-slate-200"><h3 class="text-xl font-semibold text-center text-slate-800 mb-4">Tool Placement in the AI Lifecycle</h3><div class="flex flex-col md:flex-row justify-center items-center space-y-4 md:space-y-0 md:space-x-2 p-4 rounded-lg" id="lifecycle-diagram"><div class="lifecycle-stage bg-slate-100 p-4 rounded-lg text-center w-full md:w-1/4" data-stage="dev"><h4 class="font-bold">1. Development</h4><p class="text-sm">Experimentation, prompt engineering, fine-tuning.</p></div><div class="text-2xl text-slate-400 font-mono">&gt;</div><div class="lifecycle-stage bg-slate-100 p-4 rounded-lg text-center w-full md:w-1/4" data-stage="pre-prod"><h4 class="font-bold">2. Pre-Production</h4><p class="text-sm">Testing, validation, quality assurance.</p></div><div class="text-2xl text-slate-400 font-mono">&gt;</div><div class="lifecycle-stage bg-slate-100 p-4 rounded-lg text-center w-full md:w-1/4" data-stage="post-prod"><h4 class="font-bold">3. Production</h4><p class="text-sm">Monitoring, debugging, continuous improvement.</p></div></div></div><div class="bg-white p-6 rounded-lg shadow-md border border-slate-200"><h3 class="text-xl font-semibold text-slate-800 mb-4">Explore Visualization Tools</h3><div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6" id="viz-cards"></div></div></section><section class="hidden space-y-8" id="frameworks"><div class="bg-white p-6 rounded-lg shadow-md border border-slate-200"><h2 class="text-3xl font-bold text-indigo-700 mb-2">Holistic Evaluation Frameworks</h2><p class="text-slate-600 max-w-4xl">
                    A truly robust and responsible AI system requires more than just high accuracy. Holistic evaluation frameworks provide a structured way to assess critical, often non-functional, qualities. These include ensuring the model is fair across different demographics, robust against unexpected inputs, and safe from misuse.
                </p></div><div class="bg-white p-6 rounded-lg shadow-md border border-slate-200"><h3 class="text-xl font-semibold text-center text-slate-800 mb-4">Dimensions of a Comprehensive AI Evaluation</h3><div class="flex flex-col md:flex-row items-center justify-center gap-8"><div class="chart-container flex-shrink-0" style="height: 450px; max-width: 450px;"><canvas id="frameworkChart"></canvas></div><div class="space-y-3 max-w-sm" id="framework-controls"><p class="text-slate-600">Toggle different evaluation dimensions to see how they contribute to a complete assessment strategy. A larger, more balanced shape indicates a more comprehensive evaluation.</p></div></div></div></section></main><div class="modal-backdrop hidden" id="modal"><div class="modal-content"><h2 class="text-2xl font-bold mb-4" id="modal-title"></h2><p class="text-slate-600 mb-4" id="modal-description"></p><h3 class="text-lg font-semibold mb-2">Key Focus:</h3><p class="text-slate-600 mb-4" id="modal-focus"></p><h3 class="text-lg font-semibold mb-2">Tags:</h3><div id="modal-tags"></div><button class="mt-6 w-full bg-slate-600 text-white py-2 rounded-lg hover:bg-slate-700 transition" id="modal-close">Close</button></div></div><script>
        document.addEventListener('DOMContentLoaded', () => {

            const sections = document.querySelectorAll('main > section');
            const navButtons = document.querySelectorAll('#nav-buttons .nav-btn');
            const mobileNav = document.getElementById('mobile-nav');

            const data = {
                benchmarks: [
                    { name: 'HELM', description: 'A comprehensive framework from Stanford for Holistic Evaluation of Language Models, covering a wide range of scenarios and metrics.', focus: 'Multi-metric, standardized evaluation across dozens of scenarios to assess general capabilities.', tags: ['Academia', 'General Purpose', 'Multi-task'], scores: { reasoning: 8, knowledge: 9, coding: 5, dialogue: 6, safety: 7 } },
                    { name: 'Chatbot Arena', description: 'A crowdsourced platform where humans vote on the outputs of two anonymous models, creating a leaderboard based on Elo ratings.', focus: 'Human preference in open-ended chat scenarios.', tags: ['Crowdsourced', 'Dialogue', 'Human Preference'], scores: { reasoning: 7, knowledge: 7, coding: 6, dialogue: 10, safety: 6 } },
                    { name: 'Open LLM Leaderboard', description: 'A Hugging Face initiative to track, rank, and evaluate open-source Large Language Models on a variety of benchmarks.', focus: 'Evaluating core reasoning and knowledge capabilities of open-source models.', tags: ['Open Source', 'Leaderboard', 'Reasoning'], scores: { reasoning: 9, knowledge: 8, coding: 4, dialogue: 3, safety: 4 } },
                    { name: 'MMLU', description: 'A massive multitask test consisting of multiple-choice questions from various subjects to measure knowledge acquired during pretraining.', focus: 'Measuring few-shot and zero-shot knowledge across 57 subjects.', tags: ['Knowledge', 'Multiple Choice', 'Zero-shot'], scores: { reasoning: 7, knowledge: 10, coding: 2, dialogue: 2, safety: 3 } },
                    { name: 'HumanEval', description: 'A benchmark created by OpenAI for evaluating the functional correctness of code generated by models.', focus: 'Code generation for Python, based on unit tests.', tags: ['Coding', 'Code Generation', 'Python'], scores: { reasoning: 4, knowledge: 3, coding: 10, dialogue: 1, safety: 2 } },
                    { name: 'MT-Bench', description: 'A benchmark for evaluating the multi-turn conversational and instruction-following abilities of chatbots.', focus: 'Assessing multi-turn dialogue quality with LLM-as-a-judge.', tags: ['Multi-turn', 'Dialogue', 'Instruction Following'], scores: { reasoning: 6, knowledge: 6, coding: 5, dialogue: 9, safety: 5 } },
                ],
                visualizations: [
                    { name: 'Langfuse', description: 'An open-source observability and analytics platform specifically for LLM applications. It helps in tracing, debugging, and evaluating complex chains and agents.', focus: 'Detailed tracing of LLM calls, cost analysis, and quality evaluation.', tags: ['Observability', 'Open Source', 'Tracing'], stages: ['dev', 'pre-prod', 'post-prod'] },
                    { name: 'Weights & Biases', description: 'A popular MLOps platform for tracking experiments, managing datasets, and collaborating on model development. W&B Prompts is their tool for LLM evaluation.', focus: 'Experiment tracking, prompt versioning, and visualizing model outputs.', tags: ['MLOps', 'Experiment Tracking', 'Visualization'], stages: ['dev', 'pre-prod'] },
                    { name: 'Arize AI', description: 'An ML observability platform that helps teams monitor model performance in production, troubleshoot issues, and ensure fairness.', focus: 'Production monitoring, drift detection, and performance analysis.', tags: ['ML Observability', 'Production', 'Troubleshooting'], stages: ['post-prod'] },
                    { name: 'Galileo', description: 'A data intelligence platform for NLP that helps uncover and fix data and model errors, with a focus on unstructured data and LLMs.', focus: 'Error analysis, data quality, and prompt evaluation.', tags: ['Data Quality', 'NLP', 'Error Analysis'], stages: ['dev', 'pre-prod'] },
                    { name: 'TensorBoard', description: 'TensorFlow\'s visualization toolkit that allows tracking and visualizing metrics such as loss and accuracy, model graphs, and more.', focus: 'Visualizing model training metrics and architecture.', tags: ['Deep Learning', 'Visualization', 'Training'], stages: ['dev'] },
                    { name: 'Fiddler AI', description: 'A model performance management platform that provides explainability, monitoring, and fairness analysis for ML models, including LLMs.', focus: 'Explainable AI (XAI), fairness, and performance monitoring.', tags: ['Explainability', 'Fairness', 'Monitoring'], stages: ['pre-prod', 'post-prod'] },
                ],
                frameworks: [
                    { label: 'Performance', value: 9, description: 'Core accuracy, speed, and efficiency on target tasks.' },
                    { label: 'Fairness', value: 8, description: 'Absence of unintended bias towards certain demographics.' },
                    { label: 'Robustness', value: 7, description: 'Resilience to noisy or adversarial inputs.' },
                    { label: 'Privacy', value: 6, description: 'Protection of sensitive user data.' },
                    { label: 'Explainability', value: 8, description: 'Ability to understand and interpret model decisions.' },
                    { label: 'Safety', value: 9, description: 'Prevention of harmful, unethical, or dangerous outputs (Red Teaming).' },
                    { label: 'Cost', value: 5, description: 'Computational and financial cost of training and inference.' },
                ]
            };

            let benchmarkChart, frameworkChart;

            const tagColors = {
                'Academia': 'bg-blue-100 text-blue-800', 'General Purpose': 'bg-green-100 text-green-800', 'Crowdsourced': 'bg-yellow-100 text-yellow-800',
                'Dialogue': 'bg-purple-100 text-purple-800', 'Human Preference': 'bg-pink-100 text-pink-800', 'Open Source': 'bg-orange-100 text-orange-800',
                'Leaderboard': 'bg-indigo-100 text-indigo-800', 'Reasoning': 'bg-teal-100 text-teal-800', 'Knowledge': 'bg-cyan-100 text-cyan-800',
                'Coding': 'bg-gray-100 text-gray-800', 'Multi-turn': 'bg-rose-100 text-rose-800', 'Observability': 'bg-amber-100 text-amber-800', 'Tracing': 'bg-lime-100 text-lime-800',
                'MLOps': 'bg-sky-100 text-sky-800', 'Production': 'bg-violet-100 text-violet-800',
                'default': 'bg-slate-100 text-slate-800'
            };

            const modal = document.getElementById('modal');
            const modalTitle = document.getElementById('modal-title');
            const modalDescription = document.getElementById('modal-description');
            const modalFocus = document.getElementById('modal-focus');
            const modalTags = document.getElementById('modal-tags');
            
            function showModal(item) {
                modalTitle.textContent = item.name;
                modalDescription.textContent = item.description;
                modalFocus.textContent = item.focus;
                modalTags.innerHTML = item.tags.map(tag => `<span class="tag ${tagColors[tag] || tagColors.default}">${tag}</span>`).join('');
                modal.classList.remove('hidden');
            }

            document.getElementById('modal-close').addEventListener('click', () => modal.classList.add('hidden'));
            modal.addEventListener('click', (e) => {
                if (e.target === modal) {
                    modal.classList.add('hidden');
                }
            });
            
            function showSection(targetId) {
                sections.forEach(section => {
                    section.classList.toggle('hidden', section.id !== targetId);
                });
                navButtons.forEach(btn => {
                    btn.classList.toggle('active', btn.dataset.target === targetId);
                });
                mobileNav.value = targetId;

                if (targetId === 'benchmarking' && !benchmarkChart) createBenchmarkChart();
                if (targetId === 'frameworks' && !frameworkChart) createFrameworkChart();
                if (targetId === 'benchmarking') populateBenchmarkCards();
                if (targetId === 'visualization') populateVizCards();
            }

            navButtons.forEach(btn => {
                btn.addEventListener('click', () => {
                    showSection(btn.dataset.target);
                    window.scrollTo({ top: 0, behavior: 'smooth' });
                });
            });
            mobileNav.addEventListener('change', () => {
                 showSection(mobileNav.value);
                 window.scrollTo({ top: 0, behavior: 'smooth' });
            });


            function createBenchmarkChart() {
                const ctx = document.getElementById('benchmarkChart').getContext('2d');
                const labels = data.benchmarks.map(b => b.name);
                const datasets = Object.keys(data.benchmarks[0].scores).map((key, index) => {
                    const colors = ['#14b8a6', '#f59e0b', '#6366f1', '#ec4899', '#64748b'];
                    return {
                        label: key.charAt(0).toUpperCase() + key.slice(1),
                        data: data.benchmarks.map(b => b.scores[key]),
                        backgroundColor: colors[index % colors.length],
                        borderColor: colors[index % colors.length],
                        borderWidth: 1
                    };
                });

                benchmarkChart = new Chart(ctx, {
                    type: 'bar',
                    data: {
                        labels: labels,
                        datasets: datasets
                    },
                    options: {
                        responsive: true,
                        maintainAspectRatio: false,
                        scales: {
                            x: { stacked: true },
                            y: { stacked: true, beginAtZero: true, title: { display: true, text: 'Relative Focus Score' } }
                        },
                        plugins: {
                            tooltip: {
                                callbacks: {
                                    title: function(context) {
                                        return context[0].label;
                                    },
                                    label: function(context) {
                                        return `${context.dataset.label}: ${context.raw}`;
                                    }
                                }
                            },
                            legend: {
                                position: 'bottom',
                            }
                        }
                    }
                });
            }

            function populateBenchmarkCards() {
                const container = document.getElementById('benchmark-cards');
                container.innerHTML = data.benchmarks.map(item => `
                    <div class="card bg-white p-6 rounded-lg shadow-sm border border-slate-200 cursor-pointer"><h4 class="font-bold text-lg text-slate-800">${item.name}</h4><p class="text-slate-600 text-sm mt-1 mb-3">${item.description.substring(0, 100)}...</p><div>
                            ${item.tags.map(tag => `<span class="tag ${tagColors[tag] || tagColors.default}">${tag}</span>`).join('')}
                        </div></div>
                `).join('');
                container.querySelectorAll('.card').forEach((card, index) => {
                    card.addEventListener('click', () => showModal(data.benchmarks[index]));
                });
            }

             function populateVizCards() {
                const container = document.getElementById('viz-cards');
                const stages = document.querySelectorAll('.lifecycle-stage');

                container.innerHTML = data.visualizations.map(item => `
                    <div class="card bg-white p-6 rounded-lg shadow-sm border border-slate-200 cursor-pointer" data-viz-name="${item.name}"><h4 class="font-bold text-lg text-slate-800">${item.name}</h4><p class="text-slate-600 text-sm mt-1 mb-3">${item.description.substring(0, 100)}...</p><div>
                            ${item.tags.map(tag => `<span class="tag ${tagColors[tag] || tagColors.default}">${tag}</span>`).join('')}
                        </div></div>
                `).join('');

                container.querySelectorAll('.card').forEach((card, index) => {
                    const item = data.visualizations[index];
                    card.addEventListener('click', () => showModal(item));
                    card.addEventListener('mouseenter', () => {
                         stages.forEach(stage => {
                            if (item.stages.includes(stage.dataset.stage)) {
                                stage.style.transition = 'all 0.3s ease';
                                stage.style.backgroundColor = '#fcd34d'; // amber-300
                                stage.style.transform = 'scale(1.05)';
                            }
                        });
                    });
                    card.addEventListener('mouseleave', () => {
                         stages.forEach(stage => {
                            stage.style.backgroundColor = '#f1f5f9'; // slate-100
                            stage.style.transform = 'scale(1)';
                        });
                    });
                });
            }

            function createFrameworkChart() {
                const ctx = document.getElementById('frameworkChart').getContext('2d');
                const controlsContainer = document.getElementById('framework-controls');

                let activeData = [...data.frameworks];

                function updateChart() {
                    const filteredData = data.frameworks.filter(d => {
                        const checkbox = document.getElementById(`fw-check-${d.label}`);
                        return checkbox && checkbox.checked;
                    });
                    
                    if (filteredData.length < 3) {
                       frameworkChart.data.labels = [];
                       frameworkChart.data.datasets[0].data = [];
                    } else {
                       frameworkChart.data.labels = filteredData.map(d => d.label);
                       frameworkChart.data.datasets[0].data = filteredData.map(d => d.value);
                    }
                    frameworkChart.update();
                }

                controlsContainer.innerHTML += data.frameworks.map(item => `
                    <label for="fw-check-${item.label}" class="flex items-center p-3 bg-white rounded-lg shadow-sm border border-slate-200 cursor-pointer hover:bg-slate-50"><input type="checkbox" id="fw-check-${item.label}" class="h-4 w-4 rounded border-gray-300 text-indigo-600 focus:ring-indigo-500" checked><div class="ml-3 text-sm"><span class="font-medium text-slate-900">${item.label}</span><p class="text-slate-500">${item.description}</p></div></label>
                `).join('');

                data.frameworks.forEach(item => {
                    document.getElementById(`fw-check-${item.label}`).addEventListener('change', updateChart);
                });
                
                frameworkChart = new Chart(ctx, {
                    type: 'radar',
                    data: {
                        labels: activeData.map(d => d.label),
                        datasets: [{
                            label: 'Evaluation Coverage',
                            data: activeData.map(d => d.value),
                            fill: true,
                            backgroundColor: 'rgba(99, 102, 241, 0.2)',
                            borderColor: 'rgb(99, 102, 241)',
                            pointBackgroundColor: 'rgb(99, 102, 241)',
                            pointBorderColor: '#fff',
                            pointHoverBackgroundColor: '#fff',
                            pointHoverBorderColor: 'rgb(99, 102, 241)'
                        }]
                    },
                    options: {
                        responsive: true,
                        maintainAspectRatio: false,
                        elements: {
                            line: {
                                borderWidth: 3
                            }
                        },
                        scales: {
                            r: {
                                beginAtZero: true,
                                max: 10,
                                grid: { color: '#e2e8f0' },
                                angleLines: { color: '#e2e8f0' },
                                pointLabels: {
                                    font: {
                                        size: 13,
                                        weight: '500'
                                    },
                                    color: '#475569'
                                },
                                ticks: {
                                    display: false,
                                    stepSize: 2
                                }
                            }
                        },
                        plugins: {
                            legend: {
                                display: false,
                            }
                        }
                    }
                });
            }

            showSection('overview');
        });
    </script><html><head></head><body><footer class="bg-gray-800 text-gray-300"><div class="container mx-auto px-6 py-12 lg:px-8"><div class="grid grid-cols-1 gap-8 md:grid-cols-2 lg:grid-cols-4"><div><h5 class="text-lg font-semibold text-white mb-4">Company</h5><ul class="space-y-2"><li><a class="hover:text-white hover:underline transition-colors duration-200" href="https://www.dataknobs.com/about-dataknobs/">About Us</a></li><li><a class="hover:text-white hover:underline transition-colors duration-200" href="https://www.dataknobs.com/products/value-proposition/">Value Proposition</a></li><li><a class="hover:text-white hover:underline transition-colors duration-200" href="https://www.dataknobs.com/blog/">Blog</a></li><li><a class="hover:text-white hover:underline transition-colors duration-200" href="https://www.dataknobs.com/use-cases/">Use Cases Built</a></li><li><a class="hover:text-white hover:underline transition-colors duration-200" href="https://www.dataknobs.com/about-dataknobs/leadership/">Founder</a></li></ul></div><div><h5 class="text-lg font-semibold text-white mb-4">Products</h5><ul class="space-y-2"><li><a class="hover:text-white hover:underline transition-colors duration-200" href="https://www.dataknobs.com/products/kreate/">Kreate</a></li><li><a class="hover:text-white hover:underline transition-colors duration-200" href="https://www.dataknobs.com/products/kontrols/">Kontrols</a></li><li><a class="hover:text-white hover:underline transition-colors duration-200" href="https://www.dataknobs.com/products/knobs/">Knobs</a></li><li><a class="hover:text-white hover:underline transition-colors duration-200" href="https://www.dataknobs.com/use-cases/">Case Studies</a></li></ul></div><div><h5 class="text-lg font-semibold text-white mb-4">Slides Tutorials</h5><ul class="space-y-2"><li><a class="hover:text-white hover:underline transition-colors duration-200" href="https://www.dataknobs.com/generativeai/generative-ai-101-slides.html">GenAI Slides</a></li><li><a class="hover:text-white hover:underline transition-colors duration-200" href="https://www.dataknobs.com/agent-ai/tutorials.html">Agent AI Slides</a></li><li><a class="hover:text-white hover:underline transition-colors duration-200" href="https://www.dataknobs.com/vector-database/">Vector DB Slides</a></li><li><a class="hover:text-white hover:underline transition-colors duration-200" href="https://www.dataknobs.com/generativeai/10-llms/">LLM Slides</a></li><li><a class="hover:text-white hover:underline transition-colors duration-200" href="https://www.dataknobs.com/data-products/">Data Product Slides</a></li><li><a class="hover:text-white hover:underline transition-colors duration-200" href="https://www.dataknobs.com/generativeai/10-llms/rag/">RAG Slides</a></li></ul></div><div><h5 class="text-lg font-semibold text-white mb-4">Contact Us</h5><div class="space-y-2"><p>Redmond<br/>WA, USA</p><p><a class="hover:text-white hover:underline transition-colors duration-200" href="mailto:contact@dataknobs.com">contact@dataknobs.com</a></p><p><a class="hover:text-white hover:underline transition-colors duration-200" href="tel:+14253411222">+1 (425) 341-1222</a></p></div></div></div><div class="mt-12 border-t border-gray-700 pt-8 flex flex-col items-center justify-between sm:flex-row"><p class="text-sm text-gray-400">¬© 2025 Dataknobs, Inc. All rights reserved.</p><div class="flex space-x-4 mt-4 sm:mt-0"><a class="text-gray-400 hover:text-white transition-colors duration-200" href="https://www.facebook.com/dataknobs/"><span class="sr-only">Facebook</span><svg aria-hidden="true" class="h-6 w-6" fill="currentColor" viewBox="0 0 24 24"><path clip-rule="evenodd" d="M22 12c0-5.523-4.477-10-10-10S2 6.477 2 12c0 4.991 3.657 9.128 8.438 9.878v-6.987h-2.54V12h2.54V9.797c0-2.506 1.492-3.89 3.777-3.89 1.094 0 2.238.195 2.238.195v2.46h-1.26c-1.243 0-1.63.772-1.63 1.562V12h2.773l-.443 2.89h-2.33v6.988C18.343 21.128 22 16.991 22 12z" fill-rule="evenodd"></path></svg></a><a class="text-gray-400 hover:text-white transition-colors duration-200" href="https://www.twitter.com/dataknobs/"><span class="sr-only">Twitter</span><svg aria-hidden="true" class="h-6 w-6" fill="currentColor" viewBox="0 0 24 24"><path d="M8.29 20.251c7.547 0 11.675-6.253 11.675-11.675 0-.178 0-.355-.012-.53A8.348 8.348 0 0022 5.92a8.19 8.19 0 01-2.357.646 4.118 4.118 0 001.804-2.27 8.224 8.224 0 01-2.605.996 4.107 4.107 0 00-6.993 3.743 11.65 11.65 0 01-8.457-4.287 4.106 4.106 0 001.27 5.477A4.072 4.072 0 012.8 9.713v.052a4.105 4.105 0 003.292 4.022 4.095 4.095 0 01-1.853.07 4.108 4.108 0 003.834 2.85A8.233 8.233 0 012 18.407a11.616 11.616 0 006.29 1.84"></path></svg></a><a class="text-gray-400 hover:text-white transition-colors duration-200" href="https://www.linkedin.com/company/dataknobs/"><span class="sr-only">LinkedIn</span><svg aria-hidden="true" class="h-6 w-6" fill="currentColor" viewBox="0 0 24 24"><path clip-rule="evenodd" d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.783-1.75-1.75s.784-1.75 1.75-1.75 1.75.783 1.75 1.75-.784 1.75-1.75 1.75zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z" fill-rule="evenodd"></path></svg></a></div></div></div></footer></body></html></body></html>